{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aca2cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.io import read_video\n",
    "import lightning\n",
    "import torchmetrics\n",
    "import timm\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import av\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import ast\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca9239e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    L.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a2e448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cca3f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_train_short\\\\data_train_short\\\\-220020068_456239859\\\\-220020068_456239859.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241671\\\\-220020068_456241671.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241672\\\\-220020068_456241672.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241673\\\\-220020068_456241673.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241682\\\\-220020068_456241682.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241755\\\\-220020068_456241755.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241756\\\\-220020068_456241756.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241758\\\\-220020068_456241758.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241844\\\\-220020068_456241844.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241845\\\\-220020068_456241845.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241846\\\\-220020068_456241846.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241847\\\\-220020068_456241847.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241849\\\\-220020068_456241849.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241850\\\\-220020068_456241850.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456241851\\\\-220020068_456241851.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456248657\\\\-220020068_456248657.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249667\\\\-220020068_456249667.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249692\\\\-220020068_456249692.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249693\\\\-220020068_456249693.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249716\\\\-220020068_456249716.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249719\\\\-220020068_456249719.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249720\\\\-220020068_456249720.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249732\\\\-220020068_456249732.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249733\\\\-220020068_456249733.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456249739\\\\-220020068_456249739.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456252055\\\\-220020068_456252055.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456253855\\\\-220020068_456253855.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456253876\\\\-220020068_456253876.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456254282\\\\-220020068_456254282.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456254537\\\\-220020068_456254537.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456254614\\\\-220020068_456254614.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456254621\\\\-220020068_456254621.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255332\\\\-220020068_456255332.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255338\\\\-220020068_456255338.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255339\\\\-220020068_456255339.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255340\\\\-220020068_456255340.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255341\\\\-220020068_456255341.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255344\\\\-220020068_456255344.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255346\\\\-220020068_456255346.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255349\\\\-220020068_456255349.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255389\\\\-220020068_456255389.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255391\\\\-220020068_456255391.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255392\\\\-220020068_456255392.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255393\\\\-220020068_456255393.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255394\\\\-220020068_456255394.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255395\\\\-220020068_456255395.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255396\\\\-220020068_456255396.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255399\\\\-220020068_456255399.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255400\\\\-220020068_456255400.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255401\\\\-220020068_456255401.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255402\\\\-220020068_456255402.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255403\\\\-220020068_456255403.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255405\\\\-220020068_456255405.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255407\\\\-220020068_456255407.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255409\\\\-220020068_456255409.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255410\\\\-220020068_456255410.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255411\\\\-220020068_456255411.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255412\\\\-220020068_456255412.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255414\\\\-220020068_456255414.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255766\\\\-220020068_456255766.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255767\\\\-220020068_456255767.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255773\\\\-220020068_456255773.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255779\\\\-220020068_456255779.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456255780\\\\-220020068_456255780.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256003\\\\-220020068_456256003.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256005\\\\-220020068_456256005.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256012\\\\-220020068_456256012.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256013\\\\-220020068_456256013.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256016\\\\-220020068_456256016.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256019\\\\-220020068_456256019.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256430\\\\-220020068_456256430.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256446\\\\-220020068_456256446.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256475\\\\-220020068_456256475.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256571\\\\-220020068_456256571.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256868\\\\-220020068_456256868.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456256893\\\\-220020068_456256893.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456257136\\\\-220020068_456257136.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456257137\\\\-220020068_456257137.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456257139\\\\-220020068_456257139.mp4', 'data_train_short\\\\data_train_short\\\\-220020068_456257141\\\\-220020068_456257141.mp4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = \"data_train_short\\data_train_short\"\n",
    "\n",
    "video_train_paths = glob.glob(os.path.join(train_dir, \"*\", \"*.mp4\"))\n",
    "print(video_train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32e7b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_frame_by_frame(path):\n",
    "    container = av.open(path)\n",
    "    for frame in container.decode(video=0):\n",
    "        yield frame.to_ndarray(format=\"rgb24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bf56ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_safe(path, target_size=(112, 112)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame).resize(target_size)\n",
    "            frames.append(np.array(frame))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"error {path}\")\n",
    "        if len(frames) > 0:\n",
    "            return frames\n",
    "        else:\n",
    "            return None\n",
    "    finally:\n",
    "        cap.release()\n",
    "    if len(frames)>0:\n",
    "        return frames\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a95a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_videos = []\n",
    "for path in video_train_paths[0:2]:\n",
    "    video = read_video_safe(path)\n",
    "    if video is not None:\n",
    "        valid_videos.append(video)\n",
    "video_train = valid_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3915bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_frames(str):\n",
    "    h, m, s = map(int, str.split(':'))\n",
    "    return (h*3600 + m*60 + s)*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cae77ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-220020068_456239859': (360, 672), '-220020068_456241671': (4560, 5448), '-220020068_456241672': (4680, 5544), '-220020068_456241673': (3288, 4128), '-220020068_456241682': (3144, 3720), '-220020068_456241755': (4512, 4608), '-220020068_456241756': (1584, 1680), '-220020068_456241758': (1488, 2832), '-220020068_456241844': (3936, 4032), '-220020068_456241845': (1608, 1680), '-220020068_456241846': (1800, 1896), '-220020068_456241847': (9744, 9840), '-220020068_456241849': (4392, 5736), '-220020068_456241850': (1464, 1536), '-220020068_456241851': (360, 1560), '-220020068_456248657': (3576, 3600), '-220020068_456249667': (144, 240), '-220020068_456249692': (144, 240), '-220020068_456249693': (144, 240), '-220020068_456249716': (144, 216), '-220020068_456249719': (144, 240), '-220020068_456249720': (144, 216), '-220020068_456249732': (144, 240), '-220020068_456249733': (144, 216), '-220020068_456249739': (144, 240), '-220020068_456252055': (264, 11040), '-220020068_456253855': (11808, 12264), '-220020068_456253876': (17976, 18432), '-220020068_456254282': (4536, 4776), '-220020068_456254537': (3096, 3360), '-220020068_456254614': (12048, 12456), '-220020068_456254621': (10608, 11016), '-220020068_456255332': (3480, 4248), '-220020068_456255338': (2304, 2448), '-220020068_456255339': (240, 480), '-220020068_456255340': (264, 504), '-220020068_456255341': (240, 504), '-220020068_456255344': (2088, 2712), '-220020068_456255346': (2064, 2664), '-220020068_456255349': (3144, 3768), '-220020068_456255389': (0, 192), '-220020068_456255391': (2640, 2760), '-220020068_456255392': (2640, 2760), '-220020068_456255393': (2640, 2760), '-220020068_456255394': (1440, 2640), '-220020068_456255395': (1536, 1608), '-220020068_456255396': (2592, 2640), '-220020068_456255399': (408, 528), '-220020068_456255400': (408, 528), '-220020068_456255401': (408, 528), '-220020068_456255402': (408, 528), '-220020068_456255403': (384, 528), '-220020068_456255405': (384, 528), '-220020068_456255407': (408, 528), '-220020068_456255409': (2448, 2568), '-220020068_456255410': (2472, 2688), '-220020068_456255411': (2448, 2568), '-220020068_456255412': (2448, 2688), '-220020068_456255414': (2448, 2568), '-220020068_456255766': (4344, 4584), '-220020068_456255767': (1632, 2832), '-220020068_456255773': (3000, 3240), '-220020068_456255779': (1560, 1800), '-220020068_456255780': (2400, 2616), '-220020068_456256003': (5064, 5208), '-220020068_456256005': (5952, 6096), '-220020068_456256012': (6144, 6288), '-220020068_456256013': (4800, 4944), '-220020068_456256016': (6528, 6672), '-220020068_456256019': (3624, 3792), '-220020068_456256430': (10512, 10872), '-220020068_456256446': (7800, 8184), '-220020068_456256475': (15000, 15408), '-220020068_456256571': (6384, 6792), '-220020068_456256868': (3984, 4224), '-220020068_456256893': (2424, 2664), '-220020068_456257136': (8712, 8904), '-220020068_456257137': (2880, 4152), '-220020068_456257139': (5880, 6072), '-220020068_456257141': (6240, 6408)}\n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\UCHYOBA\\VK\\labels_json\\labels_json\\train_labels.json\", \"r\", encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    data = ast.literal_eval(content)\n",
    "    result = {key: (min(time_to_frames(val[\"start\"]), time_to_frames(val[\"end\"])),\n",
    "                    max(time_to_frames(val[\"start\"]), time_to_frames(val[\"end\"])))\n",
    "    for key, val in data.items()\n",
    "}\n",
    "\n",
    "sorted_data = {k: result[k] for k in sorted(result)}\n",
    "print(sorted_data)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04521a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntroDataset(Dataset):\n",
    "    def __init__(self, videos, labels_dict, filenames, clip_len=16, fps=24, transform=None):\n",
    "        self.clip_len = clip_len\n",
    "        self.fps = fps\n",
    "        self.transform = transform\n",
    "\n",
    "        self.samples = []\n",
    "\n",
    "        for idx, video_frames in enumerate(videos):\n",
    "            name = filenames[idx]\n",
    "            if name not in labels_dict:\n",
    "                continue\n",
    "            label_range = labels_dict[name]\n",
    "            frames = np.array(video_frames) \n",
    "            for start_idx in range(0, len(frames) - clip_len + 1):\n",
    "                clip = frames[start_idx:start_idx + clip_len]\n",
    "                overlap = sum([\n",
    "                    1 for i in range(start_idx, start_idx + clip_len)\n",
    "                    if label_range[0] <= i <= label_range[1]\n",
    "                ])\n",
    "                label = 1.0 if overlap / clip_len >= 0.5 else 0.0\n",
    "\n",
    "                self.samples.append((clip, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clip, label = self.samples[idx]\n",
    "        clip = clip.transpose(3, 0, 1, 2)\n",
    "        clip = torch.from_numpy(clip).float()\n",
    "        if self.transform:\n",
    "            clip = self.transform(clip)\n",
    "        return clip, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.IntroDataset object at 0x000002BD4AB6AC10>\n"
     ]
    }
   ],
   "source": [
    "filenames = [os.path.splitext(os.path.basename(path))[0] for path in video_train_paths[0:2]]\n",
    "\n",
    "\n",
    "dataset = IntroDataset(\n",
    "    videos=video_train,\n",
    "    labels_dict=sorted_data,\n",
    "    filenames=filenames,\n",
    "    clip_len=16,\n",
    "    fps=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7e4f1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "64409\n",
      "(0.018630936670341103, 0.9813690633296589)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "intro_frames = sum((sorted_data[name][1]-sorted_data[name][0]) for name in filenames)\n",
    "print(intro_frames)\n",
    "all_frames = sum(len(video) for video in video_train)\n",
    "print(all_frames)\n",
    "weights = intro_frames/all_frames, 1-intro_frames/all_frames \n",
    "print(weights)\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "225ffad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=4, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59eed993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.video.r3d_18\n",
    "model.fc = nn.Linear(512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090dd1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
