Требовалось разработать метод поиска коротких заставок в сериалах. Я использовал предобученную модель R3D-18 из torchvision.models.video. Модель была дообучена на предоставленных данных для предсказания временных меток заставок. Для реализации использовались PyTorch и PyTorch Lightning.

Загрузка данных:
Каждое видео при преобразовании его в кадры начинало весить очень много (сотни Гб). Для этого кадры сжимались - место для хранения уменьшалось, но информативность оставалась 

R3D-18 использовалась из-за своей особенности работы с данными: в неё можно подавать клипы из 16 кадров, каждому из которых она присвоит метку заставка(1)/не заставка(0). Так как размеченные данные ставят начало и конец с точностью до секунды, это можно использовать, потому что 16 кадров это меньше 1 секунды видео (стандартные fps для кино, если не ошибаюсь, 24).

После обработки (нормализация, сжатие), к R3D-18 можно добавить полносвязный слой, имеющий 1 выходом, с вероятностью, соответствующей классификации.

Считая, что fps = 24, переведем время начала и конца в начальный и конечный кадр заставки. После разбиения на клипы по 16 кадров будем смотреть на то, какой из клипов классификатор пометил как заставку. 

В качестве loss-функции можно использовать IoU(Intersection - пересечение кадров заставки реальной и предсказанной, Union - объединение), loss = I/U

У нас наблюдается явный дисбаланс в сторону класса "0".